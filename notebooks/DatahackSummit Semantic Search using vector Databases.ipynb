{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e03b93",
   "metadata": {},
   "source": [
    "# Building Your Own Search Engine Using Vector Databases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e8918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T08:40:26.682054Z",
     "start_time": "2023-07-05T08:40:26.542951Z"
    }
   },
   "source": [
    "![img](https://www.analyticsvidhya.com/datahack-summit-2023/wp-content/uploads/2023/07/s-won_searchengin.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef2022",
   "metadata": {},
   "source": [
    "## Agenda \n",
    "\n",
    "**Part 0: The Beginning**\n",
    "\n",
    "Welcome and Objectives : An introduction to the session's aims, a brief ice breaker activity, and setting the stage for the exploration ahead.\n",
    "\n",
    "Context Setting: A quick overview of AI, Search Engines, the current landscape, potential use-cases, benefits, and challenges. Highlight the significance of building an AI search engine with your data.\n",
    "\n",
    "**Part 1: Understanding the Basics**\n",
    "\n",
    "NLP and Search Engines: Explore the components like Natural Language Processing (NLP), Machine Learning algorithms, and their roles in crafting an efficient AI search engine. Topics include\n",
    "\n",
    "\n",
    "- What are vector embeddings?\n",
    "- Legacy vectorizing techniques like CountVectorizer, bag of words\n",
    "- Similarity measures and how do they work\n",
    "- LLM and Transformers\n",
    "\n",
    "Vector Databases\n",
    "  - An Exploration:\n",
    "  - Unveiling Vector Databases\n",
    "  - Understanding their workings\n",
    "  - Real-world use-cases\n",
    "  - A comparative analysis of available options\n",
    "\n",
    "**Part 2: Indexing**\n",
    "\n",
    "Splitting the data : Why is it required and different kinds of Data splitting. Also cover why splitting is context dependent (i.e depends on data)\n",
    "\n",
    "The next step is to insert the data into the database\n",
    "\n",
    "\n",
    "**Part 3: Searching**\n",
    "\n",
    "Performing Semantic Search on Indexed Data: Discuss and code the integration of NLP and Machine Learning algorithms into the search engine to comprehend, analyze, and generate precise search results from the given data. Employ Command line tools (or maybe a GUI) to execute the searches.\n",
    "\n",
    "Discuss Different Retrieval algorithms such as\n",
    "* MMR\n",
    "* LLM Aided Retrieval\n",
    "* Compression\n",
    "\n",
    "**Part 4: Question and answering**\n",
    "\n",
    "- Prompt Engineering and templates \n",
    "- Addressing a lot of windows and short context windows\n",
    "\n",
    "**Part 5: Chat**\n",
    "\n",
    "- Introducing memory\n",
    "- Followup conversations\n",
    "\n",
    "\n",
    "**Wrap-Up and Next Steps**\n",
    "\n",
    "Conclusion and Future Directions: Discuss steps to enhance the solution and where to go from here, providing a clear path for continued exploration and development.\n",
    "\n",
    "**References and Resources**\n",
    "\n",
    "\n",
    "## Checkbox\n",
    "\n",
    "\n",
    "### Demo Checkbox\n",
    "\n",
    "- [X]  **Part 1: Understanding the Basics**\n",
    "- [X]  **Part 2: Indexing**\n",
    "- [X]  **Part 3: Semantic search with vector db**\n",
    "- [X]  **Part 4: Question and answering**\n",
    "- [X]  **Part 5: Chat**\n",
    "\n",
    "\n",
    "### Theory material Checkbox\n",
    "\n",
    "- [X]  **Part 1: Understanding the Basics**\n",
    "- [X]  **Part 2: Indexing**\n",
    "- [X]  **Part 3: Semantic search with vector db**\n",
    "- [X]  **Part 4: Question and answering**\n",
    "- [X]  **Part 5: Chat**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64b282",
   "metadata": {},
   "source": [
    "## Libraries and Technologies we will use\n",
    "\n",
    "1) Pre Trained Large Language Model (LLM) like ChatGPT for vector Embedding\n",
    "2) Langchain for Supporting our model application\n",
    "3) Vector Database like Chroma\n",
    "4) Gradio\n",
    "\n",
    "\n",
    "## Generic Architecture\n",
    "\n",
    "![arch](https://ghost.hacksoft.io/content/images/2023/04/answering_questions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb888ac7",
   "metadata": {},
   "source": [
    "# Hands On Coding\n",
    "\n",
    "## Dependencies Installation and Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fcfbe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:41.092489Z",
     "start_time": "2023-07-30T19:27:41.088617Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install langchain openai chromadb kaggle sentence_transformers datasets gradio elasticsearch tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3134955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:41.102590Z",
     "start_time": "2023-07-30T19:27:41.097930Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "if not os.path.isfile(\"database.sqlite\"):\n",
    "    os.system(\"kaggle datasets download benhamner/nips-papersv\")\n",
    "    os.system(\"unzip -o nips-papers.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26bdddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:43.767420Z",
     "start_time": "2023-07-30T19:27:41.107574Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "import sqlite3\n",
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b4e167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:44.960915Z",
     "start_time": "2023-07-30T19:27:43.770199Z"
    }
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"database.sqlite\")\n",
    "\n",
    "sql= \"\"\"WITH paper_author_list AS (\n",
    "    SELECT papers.id AS paper_id, Group_concat(authors.name) AS author_list\n",
    "    FROM papers\n",
    "    JOIN paper_authors ON papers.id = paper_authors.paper_id\n",
    "    JOIN authors ON paper_authors.author_id = authors.id\n",
    "    GROUP BY paper_id\n",
    ")\n",
    "SELECT papers.id AS paper_id, papers.year, papers.title, papers.abstract, papers.paper_text, paper_author_list.author_list AS authors\n",
    "FROM papers\n",
    "JOIN paper_author_list ON papers.id = paper_author_list.paper_id\n",
    "WHERE abstract NOT LIKE '%Abstract Missing%'\n",
    "\n",
    "\"\"\";\n",
    "\n",
    "papers_df = pd.read_sql_query(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481493fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:44.981885Z",
     "start_time": "2023-07-30T19:27:44.963059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Algorithms for Non-negative Matrix Factorization</td>\n",
       "      <td>Non-negative matrix factorization (NMF) has pr...</td>\n",
       "      <td>Algorithms for Non-negative Matrix\\nFactorizat...</td>\n",
       "      <td>Daniel D. Lee,H. Sebastian Seung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
       "      <td>Spike-triggered averaging techniques are effec...</td>\n",
       "      <td>Characterizing neural gain control using\\nspik...</td>\n",
       "      <td>Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Competition Adds Complexity</td>\n",
       "      <td>It is known that determinining whether a DEC-P...</td>\n",
       "      <td>Competition adds complexity\\n\\nJudy Goldsmith\\...</td>\n",
       "      <td>Judy Goldsmith,Martin Mundhenk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "      <td>We present the first truly polynomial algorith...</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "      <td>Anton Chechetka,Carlos Guestrin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning</td>\n",
       "      <td>Semi-supervised inductive learning concerns ho...</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning...</td>\n",
       "      <td>Ke Chen,Shihai Wang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  year                                              title  \\\n",
       "0      1861  2000   Algorithms for Non-negative Matrix Factorization   \n",
       "1      1975  2001  Characterizing Neural Gain Control using Spike...   \n",
       "2      3163  2007                        Competition Adds Complexity   \n",
       "3      3164  2007  Efficient Principled Learning of Thin Junction...   \n",
       "4      3167  2007     Regularized Boost for Semi-Supervised Learning   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Non-negative matrix factorization (NMF) has pr...   \n",
       "1  Spike-triggered averaging techniques are effec...   \n",
       "2  It is known that determinining whether a DEC-P...   \n",
       "3  We present the first truly polynomial algorith...   \n",
       "4  Semi-supervised inductive learning concerns ho...   \n",
       "\n",
       "                                          paper_text  \\\n",
       "0  Algorithms for Non-negative Matrix\\nFactorizat...   \n",
       "1  Characterizing neural gain control using\\nspik...   \n",
       "2  Competition adds complexity\\n\\nJudy Goldsmith\\...   \n",
       "3  Efficient Principled Learning of Thin Junction...   \n",
       "4  Regularized Boost for Semi-Supervised Learning...   \n",
       "\n",
       "                                             authors  \n",
       "0                   Daniel D. Lee,H. Sebastian Seung  \n",
       "1  Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...  \n",
       "2                     Judy Goldsmith,Martin Mundhenk  \n",
       "3                    Anton Chechetka,Carlos Guestrin  \n",
       "4                                Ke Chen,Shihai Wang  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58712470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:44.989026Z",
     "start_time": "2023-07-30T19:27:44.983972Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process_text(papers_df, column):\n",
    "    \n",
    "    # Load the regular expression library\n",
    "    import re\n",
    "    preprocessed_column = f\"{column}_processed\"\n",
    "\n",
    "    # Print the titles of the first rows \n",
    "    print(papers_df[column].head())\n",
    "\n",
    "    # remove punctuations\n",
    "    #papers_df[preprocessed_column] = papers_df[column].map(lambda x: re.sub('[,!?]', '', x))\n",
    "    \n",
    "     # remove carriage return and end of line\n",
    "    papers_df[preprocessed_column] = papers_df[column].map(lambda x: re.sub('[\\r\\n]', ' ', x))\n",
    "    \n",
    "     # remove double spaces\n",
    "    papers_df[preprocessed_column] = papers_df[preprocessed_column].map(lambda x: re.sub('  ', ' ', x))\n",
    "\n",
    "    \n",
    "    # remove para continuation\n",
    "    papers_df[preprocessed_column] = papers_df[preprocessed_column].map(lambda x: re.sub('- ', '', x))\n",
    "\n",
    "    # Convert the titles to lowercase\n",
    "    papers_df[preprocessed_column] = papers_df[preprocessed_column].map(lambda x: x.lower())\n",
    "    return papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1362e65f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:47.656061Z",
     "start_time": "2023-07-30T19:27:44.991102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Algorithms for Non-negative Matrix Factorization\n",
      "1    Characterizing Neural Gain Control using Spike...\n",
      "2                          Competition Adds Complexity\n",
      "3    Efficient Principled Learning of Thin Junction...\n",
      "4       Regularized Boost for Semi-Supervised Learning\n",
      "Name: title, dtype: object\n",
      "0    Non-negative matrix factorization (NMF) has pr...\n",
      "1    Spike-triggered averaging techniques are effec...\n",
      "2    It is known that determinining whether a DEC-P...\n",
      "3    We present the first truly polynomial algorith...\n",
      "4    Semi-supervised inductive learning concerns ho...\n",
      "Name: abstract, dtype: object\n",
      "0    Algorithms for Non-negative Matrix\\nFactorizat...\n",
      "1    Characterizing neural gain control using\\nspik...\n",
      "2    Competition adds complexity\\n\\nJudy Goldsmith\\...\n",
      "3    Efficient Principled Learning of Thin Junction...\n",
      "4    Regularized Boost for Semi-Supervised Learning...\n",
      "Name: paper_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_columns = [\"title\", \"abstract\", \"paper_text\"]\n",
    "for column in text_columns:\n",
    "    pre_process_text(papers_df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7b97d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:47.667670Z",
     "start_time": "2023-07-30T19:27:47.658131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.abstract_processed[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d05f13e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:47.685767Z",
     "start_time": "2023-07-30T19:27:47.674090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>title_processed</th>\n",
       "      <th>abstract_processed</th>\n",
       "      <th>paper_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Daniel D. Lee,H. Sebastian Seung</td>\n",
       "      <td>algorithms for non-negative matrix factorization</td>\n",
       "      <td>non-negative matrix factorization (nmf) has pr...</td>\n",
       "      <td>algorithms for non-negative matrix factorizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...</td>\n",
       "      <td>characterizing neural gain control using spike...</td>\n",
       "      <td>spike-triggered averaging techniques are effec...</td>\n",
       "      <td>characterizing neural gain control using spike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Judy Goldsmith,Martin Mundhenk</td>\n",
       "      <td>competition adds complexity</td>\n",
       "      <td>it is known that determinining whether a dec-p...</td>\n",
       "      <td>competition adds complexity judy goldsmith dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Anton Chechetka,Carlos Guestrin</td>\n",
       "      <td>efficient principled learning of thin junction...</td>\n",
       "      <td>we present the first truly polynomial algorith...</td>\n",
       "      <td>efficient principled learning of thin junction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Ke Chen,Shihai Wang</td>\n",
       "      <td>regularized boost for semi-supervised learning</td>\n",
       "      <td>semi-supervised inductive learning concerns ho...</td>\n",
       "      <td>regularized boost for semi-supervised learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  year                                            authors  \\\n",
       "0      1861  2000                   Daniel D. Lee,H. Sebastian Seung   \n",
       "1      1975  2001  Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...   \n",
       "2      3163  2007                     Judy Goldsmith,Martin Mundhenk   \n",
       "3      3164  2007                    Anton Chechetka,Carlos Guestrin   \n",
       "4      3167  2007                                Ke Chen,Shihai Wang   \n",
       "\n",
       "                                     title_processed  \\\n",
       "0   algorithms for non-negative matrix factorization   \n",
       "1  characterizing neural gain control using spike...   \n",
       "2                        competition adds complexity   \n",
       "3  efficient principled learning of thin junction...   \n",
       "4     regularized boost for semi-supervised learning   \n",
       "\n",
       "                                  abstract_processed  \\\n",
       "0  non-negative matrix factorization (nmf) has pr...   \n",
       "1  spike-triggered averaging techniques are effec...   \n",
       "2  it is known that determinining whether a dec-p...   \n",
       "3  we present the first truly polynomial algorith...   \n",
       "4  semi-supervised inductive learning concerns ho...   \n",
       "\n",
       "                                paper_text_processed  \n",
       "0  algorithms for non-negative matrix factorizati...  \n",
       "1  characterizing neural gain control using spike...  \n",
       "2  competition adds complexity judy goldsmith dep...  \n",
       "3  efficient principled learning of thin junction...  \n",
       "4  regularized boost for semi-supervised learning...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df = papers_df.drop([\"title\", \"abstract\", \"paper_text\"], axis=1)\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea936a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:47.692695Z",
     "start_time": "2023-07-30T19:27:47.687752Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_df = papers_df.rename(columns={'title_processed':'title', 'abstract_processed': 'abstract', 'paper_text_processed': 'paper_text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdac785d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:47.704031Z",
     "start_time": "2023-07-30T19:27:47.694832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Daniel D. Lee,H. Sebastian Seung</td>\n",
       "      <td>algorithms for non-negative matrix factorization</td>\n",
       "      <td>non-negative matrix factorization (nmf) has pr...</td>\n",
       "      <td>algorithms for non-negative matrix factorizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...</td>\n",
       "      <td>characterizing neural gain control using spike...</td>\n",
       "      <td>spike-triggered averaging techniques are effec...</td>\n",
       "      <td>characterizing neural gain control using spike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Judy Goldsmith,Martin Mundhenk</td>\n",
       "      <td>competition adds complexity</td>\n",
       "      <td>it is known that determinining whether a dec-p...</td>\n",
       "      <td>competition adds complexity judy goldsmith dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Anton Chechetka,Carlos Guestrin</td>\n",
       "      <td>efficient principled learning of thin junction...</td>\n",
       "      <td>we present the first truly polynomial algorith...</td>\n",
       "      <td>efficient principled learning of thin junction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Ke Chen,Shihai Wang</td>\n",
       "      <td>regularized boost for semi-supervised learning</td>\n",
       "      <td>semi-supervised inductive learning concerns ho...</td>\n",
       "      <td>regularized boost for semi-supervised learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  year                                            authors  \\\n",
       "0      1861  2000                   Daniel D. Lee,H. Sebastian Seung   \n",
       "1      1975  2001  Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...   \n",
       "2      3163  2007                     Judy Goldsmith,Martin Mundhenk   \n",
       "3      3164  2007                    Anton Chechetka,Carlos Guestrin   \n",
       "4      3167  2007                                Ke Chen,Shihai Wang   \n",
       "\n",
       "                                               title  \\\n",
       "0   algorithms for non-negative matrix factorization   \n",
       "1  characterizing neural gain control using spike...   \n",
       "2                        competition adds complexity   \n",
       "3  efficient principled learning of thin junction...   \n",
       "4     regularized boost for semi-supervised learning   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  non-negative matrix factorization (nmf) has pr...   \n",
       "1  spike-triggered averaging techniques are effec...   \n",
       "2  it is known that determinining whether a dec-p...   \n",
       "3  we present the first truly polynomial algorith...   \n",
       "4  semi-supervised inductive learning concerns ho...   \n",
       "\n",
       "                                          paper_text  \n",
       "0  algorithms for non-negative matrix factorizati...  \n",
       "1  characterizing neural gain control using spike...  \n",
       "2  competition adds complexity judy goldsmith dep...  \n",
       "3  efficient principled learning of thin junction...  \n",
       "4  regularized boost for semi-supervised learning...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861cf4a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:47.710491Z",
     "start_time": "2023-07-30T19:27:47.706316Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_df = papers_df.drop([\"paper_text\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9deb61f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:47.719487Z",
     "start_time": "2023-07-30T19:27:47.713344Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../secret/openai\") as f:\n",
    "    openai_secret = f.read().strip()\n",
    "    \n",
    "# PDF_FILE = \"../data/GenericEmailMarketting/merged_file.pdf\"\n",
    "\n",
    "# use import getpass instead\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_secret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212a593a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:47.745583Z",
     "start_time": "2023-07-30T19:27:47.721765Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "llm.openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c21d7ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:48.450008Z",
     "start_time": "2023-07-30T19:27:47.747179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the fish say when it hit the wall?\\nA: Dam!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "989397ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:49.105021Z",
     "start_time": "2023-07-30T19:27:48.453212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nThe current Prime Minister of the United Kingdom is Boris Johnson.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Who is the current prime minister of Britain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7921616",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:49.112884Z",
     "start_time": "2023-07-30T19:27:49.108669Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "def get_openai_embedding(text):\n",
    "   text_rep = text.replace(\"\\n\", \" \")\n",
    "   return embeddings_model.embed_documents([text_rep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a49a512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:49.117958Z",
     "start_time": "2023-07-30T19:27:49.115224Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence1 = \"i like summer\"\n",
    "sentence2 = \"Brocholi on pizza is probably not a good idea\"\n",
    "sentence3 = \"I love the warm weather outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f66b98be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.193136Z",
     "start_time": "2023-07-30T19:27:49.120711Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding1 = embeddings_model.embed_query(sentence1)\n",
    "embedding2 = embeddings_model.embed_query(sentence2)\n",
    "embedding3 = embeddings_model.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "094e1686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.204664Z",
     "start_time": "2023-07-30T19:27:50.195651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7065412380498463\n",
      "0.7131438797298986\n",
      "0.8758719352747321\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(embedding1, embedding2))\n",
    "print(np.dot(embedding2, embedding3))\n",
    "print(np.dot(embedding1, embedding3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606365d1",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dc5321d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.211767Z",
     "start_time": "2023-07-30T19:27:50.208676Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efbdd543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.218513Z",
     "start_time": "2023-07-30T19:27:50.215316Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataFrameLoader(papers_df, page_content_column=\"abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d09697be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.565202Z",
     "start_time": "2023-07-30T19:27:50.221079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use lazy load for larger table, which won't read the full table into memory \n",
    "page = loader.load()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b063e7e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.570824Z",
     "start_time": "2023-07-30T19:27:50.567247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence. '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92c593b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.577398Z",
     "start_time": "2023-07-30T19:27:50.572937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_id': 1861,\n",
       " 'year': 2000,\n",
       " 'authors': 'Daniel D. Lee,H. Sebastian Seung',\n",
       " 'title': 'algorithms for non-negative matrix factorization'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "620c0386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.583178Z",
     "start_time": "2023-07-30T19:27:50.579493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.Document"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993d2d2",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c56d3",
   "metadata": {},
   "source": [
    "### Why do we need to split the data\n",
    "1) Chatgpt and LLM have limits\n",
    "\n",
    "\n",
    "\n",
    "2) To allow for efficient search for vector spaces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aa73477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.595030Z",
     "start_time": "2023-07-30T19:27:50.592163Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6dfe267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.600288Z",
     "start_time": "2023-07-30T19:27:50.597394Z"
    }
   },
   "outputs": [],
   "source": [
    "r_spltter = RecursiveCharacterTextSplitter( # Set a really small chunk size, just to show.\n",
    "    chunk_size = 26,\n",
    "    chunk_overlap  = 4,\n",
    "    length_function = len,\n",
    "    #seperators=['\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 26,\n",
    "    chunk_overlap  = 4,\n",
    "    length_function = len,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90acef87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.605754Z",
     "start_time": "2023-07-30T19:27:50.602698Z"
    }
   },
   "outputs": [],
   "source": [
    "text_a2z = 'abcdefghijklmnopqrstuvwxyz'\n",
    "text_a2z_plus = 'abcdefghijklmnopqrstuvwxyz 12345678'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74f2a024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.613056Z",
     "start_time": "2023-07-30T19:27:50.608571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(text_a2z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25a2e5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.619821Z",
     "start_time": "2023-07-30T19:27:50.615583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', '12345678']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(text_a2z_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "491d7b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.625340Z",
     "start_time": "2023-07-30T19:27:50.621735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text_a2z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e07b0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.632111Z",
     "start_time": "2023-07-30T19:27:50.627395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz 12345678']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text_a2z_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1f09e",
   "metadata": {},
   "source": [
    "The issue is Character text splitter splits only on new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89eebdef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.637592Z",
     "start_time": "2023-07-30T19:27:50.634888Z"
    }
   },
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 26,\n",
    "    chunk_overlap  = 4,\n",
    "    length_function = len,\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "012f4002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.643695Z",
     "start_time": "2023-07-30T19:27:50.639776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', '12345678']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text_a2z_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d14ea5dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.652909Z",
     "start_time": "2023-07-30T19:27:50.648074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence. '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = page.page_content\n",
    "\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7ba264c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.660285Z",
     "start_time": "2023-07-30T19:27:50.655602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix',\n",
       " 'factorization (nmf) has',\n",
       " 'has previously been shown',\n",
       " 'to  be a useful',\n",
       " 'decomposition for',\n",
       " 'for multivariate data.',\n",
       " 'two different multi',\n",
       " 'plicative algorithms for',\n",
       " 'for nmf are analyzed.',\n",
       " 'they differ only slightly',\n",
       " 'in  the multiplicative',\n",
       " 'factor used in the update',\n",
       " 'rules. one algorithm can',\n",
       " 'can be  shown to minimize',\n",
       " 'the conventional least',\n",
       " 'squares error while the',\n",
       " 'the other  minimizes the',\n",
       " 'the generalized',\n",
       " 'kullback-leibler',\n",
       " 'divergence. the monotonic',\n",
       " 'convergence of both',\n",
       " 'algorithms can be proven',\n",
       " 'using an auxiliary func',\n",
       " 'tion analogous to that',\n",
       " 'used for proving',\n",
       " 'convergence of the',\n",
       " 'the expectation',\n",
       " 'maximization algorithm.',\n",
       " 'the algorithms can also',\n",
       " 'be interpreted as diag',\n",
       " 'onally rescaled gradient',\n",
       " 'descent, where the',\n",
       " 'the rescaling factor is',\n",
       " 'is optimally  chosen to',\n",
       " 'to ensure convergence.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "844da99d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.667044Z",
     "start_time": "2023-07-30T19:27:50.662377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix',\n",
       " 'factorization (nmf) has',\n",
       " 'has previously been shown',\n",
       " 'to be a useful',\n",
       " 'decomposition for',\n",
       " 'for multivariate data. two',\n",
       " 'two different multi',\n",
       " 'plicative algorithms for',\n",
       " 'for nmf are analyzed. they',\n",
       " 'they differ only slightly',\n",
       " 'in the multiplicative',\n",
       " 'factor used in the update',\n",
       " 'rules. one algorithm can',\n",
       " 'can be shown to minimize',\n",
       " 'the conventional least',\n",
       " 'squares error while the',\n",
       " 'the other minimizes the',\n",
       " 'the generalized',\n",
       " 'kullback-leibler',\n",
       " 'divergence. the monotonic',\n",
       " 'convergence of both',\n",
       " 'both algorithms can be',\n",
       " 'be proven using an',\n",
       " 'an auxiliary func tion',\n",
       " 'tion analogous to that',\n",
       " 'that used for proving',\n",
       " 'convergence of the',\n",
       " 'the expectation',\n",
       " 'maximization algorithm.',\n",
       " 'the algorithms can also be',\n",
       " 'be interpreted as diag',\n",
       " 'diag onally rescaled',\n",
       " 'gradient descent, where',\n",
       " 'the rescaling factor is',\n",
       " 'is optimally chosen to',\n",
       " 'to ensure convergence.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6374d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.672007Z",
     "start_time": "2023-07-30T19:27:50.669115Z"
    }
   },
   "outputs": [],
   "source": [
    "r_spltter = RecursiveCharacterTextSplitter( # Set a really small chunk size, just to show.\n",
    "   \n",
    "    length_function = len,\n",
    "    separators=['\\n\\n', \"\\n\", \" \", \"\"],\n",
    "     chunk_size = 150,\n",
    "    chunk_overlap  = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5770388e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.679092Z",
     "start_time": "2023-07-30T19:27:50.674194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative',\n",
       " 'algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to',\n",
       " 'minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of',\n",
       " 'both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm.',\n",
       " 'the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure',\n",
       " 'convergence.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7177ee16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.685281Z",
     "start_time": "2023-07-30T19:27:50.681422Z"
    }
   },
   "outputs": [],
   "source": [
    "r_spltter = RecursiveCharacterTextSplitter( # Set a really small chunk size, just to show.\n",
    "    length_function = len,\n",
    "    separators=['\\n\\n', \"\\n\", \" \",\"\\.\", \"\"],\n",
    "     chunk_size = 1000,\n",
    "    chunk_overlap  = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b438550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.691339Z",
     "start_time": "2023-07-30T19:27:50.687514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0b58bd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.697223Z",
     "start_time": "2023-07-30T19:27:50.693560Z"
    }
   },
   "outputs": [],
   "source": [
    "# what if we want to split by sentences\n",
    "# regex with look behind\n",
    "sentence_spltter = RecursiveCharacterTextSplitter( # Set a really small chunk size, just to show.\n",
    "    length_function = len,\n",
    "    separators=[\"(?<=\\.)\"],\n",
    "     chunk_size = 150,\n",
    "    chunk_overlap  = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b77495da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.703783Z",
     "start_time": "2023-07-30T19:27:50.699458Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data.',\n",
       " 'two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules.',\n",
       " 'one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence.',\n",
       " ' the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm.',\n",
       " ' the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_spltter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34f6472a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:50.708346Z",
     "start_time": "2023-07-30T19:27:50.705861Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b8a069a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.076188Z",
     "start_time": "2023-07-30T19:27:50.709942Z"
    }
   },
   "outputs": [],
   "source": [
    "token_text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f7c5c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.092417Z",
     "start_time": "2023-07-30T19:27:51.081195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc',\n",
       " 'def',\n",
       " 'gh',\n",
       " 'ij',\n",
       " 'kl',\n",
       " 'mn',\n",
       " 'op',\n",
       " 'q',\n",
       " 'r',\n",
       " 'st',\n",
       " 'uv',\n",
       " 'w',\n",
       " 'xy',\n",
       " 'z']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text_splitter.split_text(text_a2z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef5a7247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.101912Z",
     "start_time": "2023-07-30T19:27:51.095523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non',\n",
       " '-',\n",
       " 'negative',\n",
       " ' matrix',\n",
       " ' factor',\n",
       " 'ization',\n",
       " ' (',\n",
       " 'nm',\n",
       " 'f',\n",
       " ')',\n",
       " ' has',\n",
       " ' previously',\n",
       " ' been',\n",
       " ' shown',\n",
       " ' to',\n",
       " ' ',\n",
       " ' be',\n",
       " ' a',\n",
       " ' useful',\n",
       " ' decom',\n",
       " 'position',\n",
       " ' for',\n",
       " ' mult',\n",
       " 'ivariate',\n",
       " ' data',\n",
       " '.',\n",
       " ' two',\n",
       " ' different',\n",
       " ' multi',\n",
       " ' pl',\n",
       " 'icative',\n",
       " ' algorithms',\n",
       " ' for',\n",
       " ' nm',\n",
       " 'f',\n",
       " ' are',\n",
       " ' analyzed',\n",
       " '.',\n",
       " ' they',\n",
       " ' differ',\n",
       " ' only',\n",
       " ' slightly',\n",
       " ' in',\n",
       " ' ',\n",
       " ' the',\n",
       " ' multipl',\n",
       " 'icative',\n",
       " ' factor',\n",
       " ' used',\n",
       " ' in',\n",
       " ' the',\n",
       " ' update',\n",
       " ' rules',\n",
       " '.',\n",
       " ' one',\n",
       " ' algorithm',\n",
       " ' can',\n",
       " ' be',\n",
       " ' ',\n",
       " ' shown',\n",
       " ' to',\n",
       " ' minimize',\n",
       " ' the',\n",
       " ' conventional',\n",
       " ' least',\n",
       " ' squares',\n",
       " ' error',\n",
       " ' while',\n",
       " ' the',\n",
       " ' other',\n",
       " ' ',\n",
       " ' minim',\n",
       " 'izes',\n",
       " ' the',\n",
       " ' generalized',\n",
       " ' k',\n",
       " 'ull',\n",
       " 'back',\n",
       " '-',\n",
       " 'le',\n",
       " 'ib',\n",
       " 'ler',\n",
       " ' divergence',\n",
       " '.',\n",
       " ' the',\n",
       " ' mon',\n",
       " 'ot',\n",
       " 'onic',\n",
       " ' ',\n",
       " ' convergence',\n",
       " ' of',\n",
       " ' both',\n",
       " ' algorithms',\n",
       " ' can',\n",
       " ' be',\n",
       " ' proven',\n",
       " ' using',\n",
       " ' an',\n",
       " ' auxiliary',\n",
       " ' func',\n",
       " ' tion',\n",
       " ' analogous',\n",
       " ' to',\n",
       " ' that',\n",
       " ' used',\n",
       " ' for',\n",
       " ' proving',\n",
       " ' convergence',\n",
       " ' of',\n",
       " ' the',\n",
       " ' expectation',\n",
       " ' maxim',\n",
       " 'ization',\n",
       " ' algorithm',\n",
       " '.',\n",
       " ' the',\n",
       " ' algorithms',\n",
       " ' can',\n",
       " ' also',\n",
       " ' be',\n",
       " ' interpreted',\n",
       " ' as',\n",
       " ' di',\n",
       " 'ag',\n",
       " ' on',\n",
       " 'ally',\n",
       " ' resc',\n",
       " 'aled',\n",
       " ' gradient',\n",
       " ' descent',\n",
       " ',',\n",
       " ' where',\n",
       " ' the',\n",
       " ' resc',\n",
       " 'aling',\n",
       " ' factor',\n",
       " ' is',\n",
       " ' optim',\n",
       " 'ally',\n",
       " ' ',\n",
       " ' chosen',\n",
       " ' to',\n",
       " ' ensure',\n",
       " ' convergence',\n",
       " '.',\n",
       " ' ']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text_splitter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abbbe69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.467300Z",
     "start_time": "2023-07-30T19:27:51.103577Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b279b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.473653Z",
     "start_time": "2023-07-30T19:27:51.469536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3921"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb678030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.479762Z",
     "start_time": "2023-07-30T19:27:51.475798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence. ', metadata={'paper_id': 1861, 'year': 2000, 'authors': 'Daniel D. Lee,H. Sebastian Seung', 'title': 'algorithms for non-negative matrix factorization'})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b7e1dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.484848Z",
     "start_time": "2023-07-30T19:27:51.482190Z"
    }
   },
   "outputs": [],
   "source": [
    "# For simplicity we will use sentence splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f53ea8c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.970243Z",
     "start_time": "2023-07-30T19:27:51.487195Z"
    }
   },
   "outputs": [],
   "source": [
    "splits = sentence_spltter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6ee0239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:51.977236Z",
     "start_time": "2023-07-30T19:27:51.972371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data.', metadata={'paper_id': 1861, 'year': 2000, 'authors': 'Daniel D. Lee,H. Sebastian Seung', 'title': 'algorithms for non-negative matrix factorization'})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1d15f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:52.870108Z",
     "start_time": "2023-07-30T19:27:51.980004Z"
    }
   },
   "outputs": [],
   "source": [
    "random_splits = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bde27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b511cfa7",
   "metadata": {},
   "source": [
    "## Indexing data in Vectorstores\n",
    "\n",
    "### ChromaDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9565318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:27:52.875978Z",
     "start_time": "2023-07-30T19:27:52.872498Z"
    }
   },
   "outputs": [],
   "source": [
    "persist_directory_random_split_gpt = './data/chroma/random_split/gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "65b81159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:05:24.081846Z",
     "start_time": "2023-07-30T20:05:24.024842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"rm -rf {persist_directory_random_split_gpt}\")  # remove old database files if any # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "069b47e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:06:00.884365Z",
     "start_time": "2023-07-30T20:05:25.424099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 910 ms, total: 11.2 s\n",
      "Wall time: 35.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectordb_gpt = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory_random_split_gpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54ac24f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:30:55.172544Z",
     "start_time": "2023-07-30T19:30:55.164307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25143\n"
     ]
    }
   ],
   "source": [
    "print(vectordb_gpt._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abd9068c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:31:04.528283Z",
     "start_time": "2023-07-30T19:30:55.176014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33351025bcf54218a0ce354d803847f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectordb_gpt.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3fea2",
   "metadata": {},
   "source": [
    "### Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "21580e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:36:39.926574Z",
     "start_time": "2023-07-30T19:36:39.739461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"name\" : \"a1b07c8dd9e0\",\r\n",
      "  \"cluster_name\" : \"docker-cluster\",\r\n",
      "  \"cluster_uuid\" : \"TCUdzVJbQ4CZ1WorXbYDog\",\r\n",
      "  \"version\" : {\r\n",
      "    \"number\" : \"8.8.2\",\r\n",
      "    \"build_flavor\" : \"default\",\r\n",
      "    \"build_type\" : \"docker\",\r\n",
      "    \"build_hash\" : \"98e1271edf932a480e4262a471281f1ee295ce6b\",\r\n",
      "    \"build_date\" : \"2023-06-26T05:16:16.196344851Z\",\r\n",
      "    \"build_snapshot\" : false,\r\n",
      "    \"lucene_version\" : \"9.6.0\",\r\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\r\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\r\n",
      "  },\r\n",
      "  \"tagline\" : \"You Know, for Search\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET \"http://localhost:9200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d22025b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:36:45.846541Z",
     "start_time": "2023-07-30T19:36:45.837334Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import ElasticVectorSearch\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticKnnSearch\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "elastic = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "index_name = \"test_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d7a96406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:52:50.331018Z",
     "start_time": "2023-07-30T19:52:44.013857Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/q4kkg14x6c9bg29754hkb_yr0000gn/T/ipykernel_45302/2402150112.py:1: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  elastic.delete_by_query(index=[index_name], body={\"query\": {\"match_all\": {}}})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 6285, 'timed_out': False, 'total': 25174, 'deleted': 25174, 'batches': 26, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.delete_by_query(index=[index_name], body={\"query\": {\"match_all\": {}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "60a0f4ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:53:41.469644Z",
     "start_time": "2023-07-30T19:52:51.298698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.17 s, sys: 1.1 s, total: 8.27 s\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "elasticdb_gpt = ElasticVectorSearch.from_documents(\n",
    "    docs,\n",
    "    embedding,\n",
    "    index_name=index_name,\n",
    "    elasticsearch_url=\"http://localhost:9200\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302dbc1",
   "metadata": {},
   "source": [
    "go here http://localhost:5601/app/r/s/70gZ3 to see vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ebfb775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:53.567807Z",
     "start_time": "2023-07-30T19:47:53.471914Z"
    }
   },
   "outputs": [],
   "source": [
    "elastic_vector_search = ElasticVectorSearch(\n",
    "            elasticsearch_url=\"http://localhost:9200\",\n",
    "            index_name=index_name,\n",
    "            embedding=embedding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6608d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:53.580156Z",
     "start_time": "2023-07-30T19:47:53.572415Z"
    }
   },
   "outputs": [],
   "source": [
    "elastic_vector_search_knn = ElasticKnnSearch(\n",
    "\n",
    "            es_connection=elasticdb_gpt.client,\n",
    "            index_name=index_name,\n",
    "            embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca66e3",
   "metadata": {},
   "source": [
    "##  Search\n",
    "\n",
    "When a query comes in we first convert it to a vector and then compare the vector to the elements in the database to get n most similar results.\n",
    "\n",
    "**Similarity Search**\n",
    "1. Similarity Search aims to find the most similar items to a given query in a dataset.\n",
    "2. It uses metrics like cosine similarity, Jaccard similarity, or Euclidean distance to quantify similarity.\n",
    "3. The search results are ranked based on their similarity scores, and the top-K items are returned.\n",
    "4. Use-cases: When the user's intent is clear and specific, similarity search is efficient. It's commonly used in standard search engines, recommendation systems, or any scenario where the goal is to find items most similar to the query.\n",
    "\n",
    "**Maximal Marginal Relevance (MMR) Search**\n",
    "1. MMR aims to provide a diverse set of results that are relevant to the query.\n",
    "2. Along with quantifying similarity to the query, MMR also considers similarity between items in the results set to ensure diversity.\n",
    "3. It aims to maximize the relevance of the returned items to the query, but also minimize the similarity between the returned items.\n",
    "4. Use-cases: When user intent is ambiguous or when there are multiple relevant responses, MMR can provide a more diverse set of results. It's useful in news article recommendation (to avoid recommending too many similar articles) or in conversational AI (to provide diverse responses).\n",
    "\n",
    "The choice between similarity search and MMR depends on the specific use case and user needs. If the aim is to provide a diverse set of results, MMR would be more suitable. If the goal is to find items most similar to the query, a similarity search would be more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93524545",
   "metadata": {},
   "source": [
    "### Keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45f36b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:54.196727Z",
     "start_time": "2023-07-30T19:47:53.583958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keyword search\n",
    "resp = elasticdb_gpt.client.search(q=\"What is Natural language processing\", query={\"match_all\": {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9c1f4e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:54.351516Z",
     "start_time": "2023-07-30T19:47:54.200241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10000 Hits:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cross language text classi?cation is an import...</td>\n",
       "      <td>20.344220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cross language text classi?cation is an import...</td>\n",
       "      <td>20.207375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cross language text classi?cation is an import...</td>\n",
       "      <td>20.207375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Classically, tasks in natural language process...</td>\n",
       "      <td>18.876570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It obtains new state-of-the-art results on ele...</td>\n",
       "      <td>18.226519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      score\n",
       "0  cross language text classi?cation is an import...  20.344220\n",
       "1  cross language text classi?cation is an import...  20.207375\n",
       "2  cross language text classi?cation is an import...  20.207375\n",
       "3  Classically, tasks in natural language process...  18.876570\n",
       "4  It obtains new state-of-the-art results on ele...  18.226519"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Got %d Hits:\" % resp['hits']['total']['value'])\n",
    "table = []\n",
    "for hit in resp['hits']['hits']:\n",
    "    table.append([hit['_source']['text'], hit['_score']])\n",
    "table_df = pd.DataFrame(table, columns=[\"text\", \"score\"])\n",
    "\n",
    "table_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d78c45",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ffc2a094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:56.766351Z",
     "start_time": "2023-07-30T19:47:54.358483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='users want natural language processing (nlp) systems to be both fast and accurate, but quality often comes at the cost of speed.', metadata={'paper_id': 4556, 'year': 2012, 'authors': 'Jiarong Jiang,Adam Teichert,Jason Eisner,Hal Daume', 'title': 'learned prioritization for trading off accuracy and speed'}),\n",
       " Document(page_content='cross language text classi?cation is an important learning task in natural language processing.', metadata={'paper_id': 5164, 'year': 2013, 'authors': 'Min Xiao,Yuhong Guo', 'title': 'a novel two-step method for cross language representation learning'}),\n",
       " Document(page_content='our framework is inspired by state-of-the-art smoothing techniques used in natural language processing (nlp).', metadata={'paper_id': 5880, 'year': 2015, 'authors': 'Pinar Yanardag,S.V.N. Vishwanathan', 'title': 'a structural smoothing framework for robust graph comparison'}),\n",
       " Document(page_content='teaching machines to read natural language documents remains an elusive challenge.', metadata={'paper_id': 5945, 'year': 2015, 'authors': 'Karl Moritz Hermann,Tomas Kocisky,Edward Grefenstette,Lasse Espeholt,Will Kay,Mustafa Suleyman,Phil Blunsom', 'title': 'teaching machines to read and comprehend'})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_gpt.similarity_search(\"What is Natural language processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4d83dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:57.118229Z",
     "start_time": "2023-07-30T19:47:56.771988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='users want natural language processing (nlp) systems to be both fast and accurate, but quality often comes at the cost of speed.', metadata={'paper_id': 4556, 'year': 2012, 'authors': 'Jiarong Jiang,Adam Teichert,Jason Eisner,Hal Daume', 'title': 'learned prioritization for trading off accuracy and speed'}),\n",
       "  0.284382700920105),\n",
       " (Document(page_content='cross language text classi?cation is an important learning task in natural language processing.', metadata={'paper_id': 5164, 'year': 2013, 'authors': 'Min Xiao,Yuhong Guo', 'title': 'a novel two-step method for cross language representation learning'}),\n",
       "  0.28937631845474243),\n",
       " (Document(page_content='our framework is inspired by state-of-the-art smoothing techniques used in natural language processing (nlp).', metadata={'paper_id': 5880, 'year': 2015, 'authors': 'Pinar Yanardag,S.V.N. Vishwanathan', 'title': 'a structural smoothing framework for robust graph comparison'}),\n",
       "  0.30898258090019226),\n",
       " (Document(page_content='teaching machines to read natural language documents remains an elusive challenge.', metadata={'paper_id': 5945, 'year': 2015, 'authors': 'Karl Moritz Hermann,Tomas Kocisky,Edward Grefenstette,Lasse Espeholt,Will Kay,Mustafa Suleyman,Phil Blunsom', 'title': 'teaching machines to read and comprehend'}),\n",
       "  0.3155052065849304)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_gpt.similarity_search_with_score(\"What is Natural language processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "470baeb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:57.582405Z",
     "start_time": "2023-07-30T19:47:57.120656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='when used to guide decisions, linear regression analysis typically involves estimation of regression coefficients via ordinary least squares and their subsequent use to make decisions.', metadata={'paper_id': 3686, 'year': 2009, 'authors': 'Yi-hao Kao,Benjamin V. Roy,Xiang Yan', 'title': 'directed regression'}),\n",
       " Document(page_content='online sparse linear regression is the task of applying linear regression analysis to examples arriving sequentially subject to a resource constraint that a limited number of features of examples can be observed.', metadata={'paper_id': 6998, 'year': 2017, 'authors': 'Shinji Ito,Daisuke Hatano,Hanna Sumita,Akihiro Yabe,Takuro Fukunaga,Naonori Kakimura,Ken-Ichi Kawarabayashi', 'title': 'efficient sublinear-regret algorithms for online sparse linear regression with limited observation'}),\n",
       " Document(page_content='linear regression studies the problem of estimating a model parameter $\\\\beta^* \\\\in \\\\r^p$, from $n$ observations $\\\\{(y_i,x_i)\\\\}_{i=1}^n$ from linear model $y_i = \\\\langle \\\\x_i,\\\\beta^* \\\\rangle + \\\\epsilon_i$.', metadata={'paper_id': 6013, 'year': 2015, 'authors': 'Xinyang Yi,Zhaoran Wang,Constantine Caramanis,Han Liu', 'title': 'optimal linear estimation under unknown nonlinear transform'}),\n",
       " Document(page_content='the algorithm is based on linear regression and the analysis uses techniques from the linear bandit literature.', metadata={'paper_id': 6137, 'year': 2016, 'authors': 'R?my Degenne,Vianney Perchet', 'title': 'combinatorial semi-bandit with known covariance'})]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_gpt.similarity_search(\"What is linear regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ae07bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:58.360011Z",
     "start_time": "2023-07-30T19:47:57.584733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='users want natural language processing (nlp) systems to be both fast and accurate, but quality often comes at the cost of speed.', metadata={'paper_id': 4556, 'year': 2012, 'authors': 'Jiarong Jiang,Adam Teichert,Jason Eisner,Hal Daume', 'title': 'learned prioritization for trading off accuracy and speed'}),\n",
       "  1.8578087),\n",
       " (Document(page_content='cross language text classi?cation is an important learning task in natural language processing.', metadata={'paper_id': 5164, 'year': 2013, 'authors': 'Min Xiao,Yuhong Guo', 'title': 'a novel two-step method for cross language representation learning'}),\n",
       "  1.8553118),\n",
       " (Document(page_content='our framework is inspired by state-of-the-art smoothing techniques used in natural language processing (nlp).', metadata={'paper_id': 5880, 'year': 2015, 'authors': 'Pinar Yanardag,S.V.N. Vishwanathan', 'title': 'a structural smoothing framework for robust graph comparison'}),\n",
       "  1.8455409),\n",
       " (Document(page_content='teaching machines to read natural language documents remains an elusive challenge.', metadata={'paper_id': 5945, 'year': 2015, 'authors': 'Karl Moritz Hermann,Tomas Kocisky,Edward Grefenstette,Lasse Espeholt,Will Kay,Mustafa Suleyman,Phil Blunsom', 'title': 'teaching machines to read and comprehend'}),\n",
       "  1.8425978)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticdb_gpt.similarity_search_with_score(\"What is Natural language processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71f8d296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:47:58.812895Z",
     "start_time": "2023-07-30T19:47:58.362604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='users want natural language processing (nlp) systems to be both fast and accurate, but quality often comes at the cost of speed.', metadata={'paper_id': 4556, 'year': 2012, 'authors': 'Jiarong Jiang,Adam Teichert,Jason Eisner,Hal Daume', 'title': 'learned prioritization for trading off accuracy and speed'}),\n",
       "  1.8578087),\n",
       " (Document(page_content='cross language text classi?cation is an important learning task in natural language processing.', metadata={'paper_id': 5164, 'year': 2013, 'authors': 'Min Xiao,Yuhong Guo', 'title': 'a novel two-step method for cross language representation learning'}),\n",
       "  1.8553118),\n",
       " (Document(page_content='our framework is inspired by state-of-the-art smoothing techniques used in natural language processing (nlp).', metadata={'paper_id': 5880, 'year': 2015, 'authors': 'Pinar Yanardag,S.V.N. Vishwanathan', 'title': 'a structural smoothing framework for robust graph comparison'}),\n",
       "  1.8455409),\n",
       " (Document(page_content='teaching machines to read natural language documents remains an elusive challenge.', metadata={'paper_id': 5945, 'year': 2015, 'authors': 'Karl Moritz Hermann,Tomas Kocisky,Edward Grefenstette,Lasse Espeholt,Will Kay,Mustafa Suleyman,Phil Blunsom', 'title': 'teaching machines to read and comprehend'}),\n",
       "  1.8425978)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_vector_search_knn.similarity_search_with_score(\"What is Natural language processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3099ef",
   "metadata": {},
   "source": [
    "### Maximum marginal relevance\n",
    "\n",
    "Maximum marginal relevance strives to achieve both relevance to the query and diversity among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c764326d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:00.352785Z",
     "start_time": "2023-07-30T19:47:58.814888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='when used to guide decisions, linear regression analysis typically involves estimation of regression coefficients via ordinary least squares and their subsequent use to make decisions.', metadata={'paper_id': 3686, 'year': 2009, 'authors': 'Yi-hao Kao,Benjamin V. Roy,Xiang Yan', 'title': 'directed regression'}),\n",
       " Document(page_content='the algorithm is based on linear regression and the analysis uses techniques from the linear bandit literature.', metadata={'paper_id': 6137, 'year': 2016, 'authors': 'R?my Degenne,Vianney Perchet', 'title': 'combinatorial semi-bandit with known covariance'}),\n",
       " Document(page_content='we revisit isotonic regression on linear orders, the problem of fitting monotonic functions to best explain the data, in an online setting.', metadata={'paper_id': 7006, 'year': 2017, 'authors': 'Wojciech Kotlowski,Wouter M. Koolen,Alan Malek', 'title': 'random permutation online isotonic regression'}),\n",
       " Document(page_content='our method is based on recurrent linear models (rlms), and relates closely to timeseries models based on recurrent neural networks.', metadata={'paper_id': 4877, 'year': 2013, 'authors': 'Marius Pachitariu,Biljana Petreska,Maneesh Sahani', 'title': 'recurrent linear models of simultaneously-recorded neural  populations'})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_gpt.max_marginal_relevance_search(\"What is linear regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a35827dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:01.091405Z",
     "start_time": "2023-07-30T19:48:00.355537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='users want natural language processing (nlp) systems to be both fast and accurate, but quality often comes at the cost of speed.', metadata={'paper_id': 4556, 'year': 2012, 'authors': 'Jiarong Jiang,Adam Teichert,Jason Eisner,Hal Daume', 'title': 'learned prioritization for trading off accuracy and speed'}),\n",
       " Document(page_content='cross language text classi?cation is an important learning task in natural language processing.', metadata={'paper_id': 5164, 'year': 2013, 'authors': 'Min Xiao,Yuhong Guo', 'title': 'a novel two-step method for cross language representation learning'}),\n",
       " Document(page_content='recurrent neural networks (rnns) have achieved state-of-the-art performances in many natural language processing tasks, such as language modeling and machine translation.', metadata={'paper_id': 6512, 'year': 2016, 'authors': 'Xiang Li,Tao Qin,Jian Yang,Xiaolin Hu,Tieyan Liu', 'title': 'lightrnn: memory and computation-efficient recurrent neural networks'}),\n",
       " Document(page_content='our method aims at reasoning over natural language questions and visual images.', metadata={'paper_id': 6261, 'year': 2016, 'authors': 'Ruiyu Li,Jiaya Jia', 'title': 'visual question answering with question representation update (qru)'})]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_gpt.max_marginal_relevance_search(\"What is natural language processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8e95f320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:01.667043Z",
     "start_time": "2023-07-30T19:48:01.094154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_gpt.max_marginal_relevance_search(\"What is natural language processing\", filter={\"year\":1990})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc965eae",
   "metadata": {},
   "source": [
    "## Question and Answer\n",
    "\n",
    "\n",
    "When a query comes in we first convert it to a vector and then compare the vector to the elements in the database to get n most similar results. These results are then passed into prompt as a context for LLM to process them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "069a4966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:51:02.712241Z",
     "start_time": "2023-07-30T19:51:02.707368Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "llm.openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dd39a96d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:57:58.237713Z",
     "start_time": "2023-07-30T19:57:58.232290Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7980c1f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:05:05.430638Z",
     "start_time": "2023-07-30T20:05:03.091998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Linear regression is a statistical technique used to model the relationship between a response variable and one or more predictor variables. It involves estimating regression coefficients via ordinary least squares and using them to make decisions. It can also be used to predict the value of a response variable given a set of predictor variables.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "question = \"What is linear regression?\"\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=elasticdb_gpt.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5}),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "29b181e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:14:41.340629Z",
     "start_time": "2023-07-30T20:14:41.318745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='when used to guide decisions, linear regression analysis typically involves estimation of regression coefficients via ordinary least squares and their subsequent use to make decisions. when there are multiple response variables and features do not perfectly capture their relationships, it is beneficial to account for the decision objective when computing regression coefficients. empirical optimization does so but sacrifices performance when features are well-chosen or training data are insufficient. we propose directed regression, an efficient algorithm that combines merits of ordinary least squares and empirical optimization. we demonstrate through a computational study that directed regression can generate significant performance gains over either alternative. we also develop a theory that motivates the algorithm.', metadata={'paper_id': 3686, 'year': 2009, 'authors': 'Yi-hao Kao,Benjamin V. Roy,Xiang Yan', 'title': 'directed regression'}),\n",
       " Document(page_content='this article considers algorithmic and statistical aspects of linear regression when the correspondence between the covariates and the responses is unknown. first, a fully polynomial-time approximation scheme is given for the natural least squares optimization problem in any constant dimension. next, in an average-case and noise-free setting where the responses exactly correspond to a linear function of i.i.d. draws from a standard multivariate normal distribution, an efficient algorithm based on lattice basis reduction is shown to exactly recover the unknown linear function in arbitrary dimension. finally, lower bounds on the signal-to-noise ratio are established for approximate recovery of the unknown linear function by any estimator.', metadata={'paper_id': 6751, 'year': 2017, 'authors': 'Daniel J. Hsu,Kevin Shi,Xiaorui Sun', 'title': 'linear regression without correspondence'}),\n",
       " Document(page_content='linear regression studies the problem of estimating a model parameter $\\\\beta^* \\\\in \\\\r^p$, from $n$ observations $\\\\{(y_i,x_i)\\\\}_{i=1}^n$ from linear model $y_i = \\\\langle \\\\x_i,\\\\beta^* \\\\rangle + \\\\epsilon_i$. we consider a significant generalization in which the relationship between $\\\\langle x_i,\\\\beta^* \\\\rangle$ and $y_i$ is noisy, quantized to a single bit, potentially nonlinear, noninvertible, as well as unknown. this model is known as the single-index model in statistics, and, among other things, it represents a significant generalization of one-bit compressed sensing. we propose a novel spectral-based estimation procedure and show that we can recover $\\\\beta^*$ in settings (i.e., classes of link function $f$) where previous algorithms fail. in general, our algorithm requires only very mild restrictions on the (unknown) functional relationship between $y_i$ and $\\\\langle x_i,\\\\beta^* \\\\rangle$. we also consider the high dimensional setting where $\\\\beta^*$ is sparse, and introduce a two-stage nonconvex framework that addresses estimation challenges in high dimensional regimes where $p \\\\gg n$. for a broad class of link functions between $\\\\langle x_i,\\\\beta^* \\\\rangle$ and $y_i$, we establish minimax lower bounds that demonstrate the optimality of our estimators in both the classical and high dimensional regimes.', metadata={'paper_id': 6013, 'year': 2015, 'authors': 'Xinyang Yi,Zhaoran Wang,Constantine Caramanis,Han Liu', 'title': 'optimal linear estimation under unknown nonlinear transform'}),\n",
       " Document(page_content='in a regression task, a predictor is given a set of instances, along with a real value for each point. subsequently, she has to identify the value of a new instance as accurately as possible. in this work, we initiate the study of strategic predictions in machine learning. we consider a regression task tackled by two players, where the payoff of each player is the proportion of the points she predicts more accurately than the other player. we first revise the probably approximately correct learning framework to deal with the case of a duel between two predictors. we then devise an algorithm which finds a linear regression predictor that is a best response to any (not necessarily linear) regression algorithm. we show that it has linearithmic sample complexity, and polynomial time complexity when the dimension of the instances domain is fixed. we also test our approach in a high-dimensional setting, and show it significantly defeats classical regression algorithms in the prediction duel. together, our work introduces a novel machine learning task that lends itself well to current competitive online settings, provides its theoretical foundations, and illustrates its applicability.', metadata={'paper_id': 6748, 'year': 2017, 'authors': 'Omer Ben Porat,Moshe Tennenholtz', 'title': 'best response regression'}),\n",
       " Document(page_content='online sparse linear regression is the task of applying linear regression analysis to examples arriving sequentially subject to a resource constraint that a limited number of features of examples can be observed. despite its importance in many practical applications, it has been recently shown that there is no polynomial-time sublinear-regret algorithm unless np$\\\\subseteq$bpp, and only an exponential-time sublinear-regret algorithm has been found. in this paper, we introduce mild assumptions to solve the problem. under these assumptions, we present polynomial-time sublinear-regret algorithms for the online sparse linear regression. in addition, thorough experiments with publicly available data demonstrate that our algorithms outperform other known algorithms.', metadata={'paper_id': 6998, 'year': 2017, 'authors': 'Shinji Ito,Daisuke Hatano,Hanna Sumita,Akihiro Yabe,Takuro Fukunaga,Naonori Kakimura,Ken-Ichi Kawarabayashi', 'title': 'efficient sublinear-regret algorithms for online sparse linear regression with limited observation'})]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "877de9f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:44:49.514199Z",
     "start_time": "2023-07-30T20:44:49.509968Z"
    }
   },
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb_gpt.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 20}),\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"map_reduce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0c5096d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:45:27.217959Z",
     "start_time": "2023-07-30T20:44:50.928111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Linear regression is a statistical method used to predict a response variable based on one or more predictor variables. It is used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data.'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0cef0121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:46:11.133616Z",
     "start_time": "2023-07-30T20:46:11.128758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is linear regression?',\n",
       " 'result': ' Linear regression is a statistical method used to predict a response variable based on one or more predictor variables. It is used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data.'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "54827ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:46:21.389466Z",
     "start_time": "2023-07-30T20:46:21.385855Z"
    }
   },
   "outputs": [],
   "source": [
    "qa_chain_refine = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb_gpt.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 20}),\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"refine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6d5b65b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:48:12.105625Z",
     "start_time": "2023-07-30T20:46:25.231826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nLinear regression is a statistical technique used to model the relationship between a dependent variable (the response variable) and one or more independent variables (the features). It is used to predict the value of the response variable based on the values of the features. It is typically used to guide decisions by estimating regression coefficients via ordinary least squares and using them to make decisions. Additionally, linear regression studies the problem of estimating a model parameter $\\\\beta^* \\\\in \\\\r^p$, from $n$ observations $\\\\{(y_i,x_i)\\\\}_{i=1}^n$ from linear model $y_i = \\\\langle \\\\x_i,\\\\beta^* \\\\rangle + \\\\epsilon_i$. It also considers a significant generalization in log-linear models, which are widely used probability models for statistical pattern recognition. These models are typically trained according to a convex criterion, and the optimization of log-linear model parameters is costly and therefore an important topic, in particular for large-scale applications. Different optimization algorithms have been evaluated empirically in many papers, and by making use of the convergence analysis, good results can be obtained on large-scale continuous handwriting recognition tasks with a simple and generic approach. Additionally'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain_refine({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "451189f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:48:22.627697Z",
     "start_time": "2023-07-30T20:48:22.622287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is linear regression?',\n",
       " 'result': '\\n\\nLinear regression is a statistical technique used to model the relationship between a dependent variable (the response variable) and one or more independent variables (the features). It is used to predict the value of the response variable based on the values of the features. It is typically used to guide decisions by estimating regression coefficients via ordinary least squares and using them to make decisions. Additionally, linear regression studies the problem of estimating a model parameter $\\\\beta^* \\\\in \\\\r^p$, from $n$ observations $\\\\{(y_i,x_i)\\\\}_{i=1}^n$ from linear model $y_i = \\\\langle \\\\x_i,\\\\beta^* \\\\rangle + \\\\epsilon_i$. It also considers a significant generalization in log-linear models, which are widely used probability models for statistical pattern recognition. These models are typically trained according to a convex criterion, and the optimization of log-linear model parameters is costly and therefore an important topic, in particular for large-scale applications. Different optimization algorithms have been evaluated empirically in many papers, and by making use of the convergence analysis, good results can be obtained on large-scale continuous handwriting recognition tasks with a simple and generic approach. Additionally'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "51923140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:06:34.630733Z",
     "start_time": "2023-07-30T20:06:34.623599Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "def query_db(db, users_question, llm, k=10,filter={}):\n",
    "  # define the prompt template\n",
    "  template = \"\"\"\n",
    "  Given the following context sections, answer the\n",
    "  question using only the given context. If you are unsure and the answer is not\n",
    "  explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n",
    "\n",
    "  Context sections:\n",
    "  {context}\n",
    "\n",
    "  Question:\n",
    "  {users_question}\n",
    "\n",
    "  Answer:\n",
    "  \"\"\"\n",
    "  prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
    "    # use our vector store to find similar text chunks\n",
    "  results = db.similarity_search(\n",
    "      query=users_question,\n",
    "      n_results=k,\n",
    "      filter=filter\n",
    "  )\n",
    "\n",
    "\n",
    "  # fill the prompt template\n",
    "  prompt_text = prompt.format(context = results, users_question = users_question)\n",
    "\n",
    "  # ask the defined LLM\n",
    "  return llm(prompt_text)\n",
    "\n",
    "\n",
    "def query_db_relevance(db, users_question, llm, k=10, filter={}):\n",
    "  # define the prompt template\n",
    "  template = \"\"\"\n",
    "  Given the following context sections, answer the\n",
    "  question using only the given context. If you are unsure and the answer is not\n",
    "  explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n",
    "\n",
    "  Context sections:\n",
    "  {context}\n",
    "\n",
    "  Question:\n",
    "  {users_question}\n",
    "\n",
    "  Answer:\n",
    "  \"\"\"\n",
    "  prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
    "    # use our vector store to find similar text chunks\n",
    "  results = db.max_marginal_relevance_search(\n",
    "      query=users_question,\n",
    "      n_results=k,\n",
    "      filter=filter\n",
    "  )\n",
    "\n",
    "  # fill the prompt template\n",
    "  prompt_text = prompt.format(context = results, users_question = users_question)\n",
    "\n",
    "  # ask the defined LLM\n",
    "  return llm(prompt_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "76d64bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T20:07:07.588918Z",
     "start_time": "2023-07-30T20:07:04.490975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Linear regression is a method of estimating a model parameter from observations of a linear model, where the relationship between the covariates and the responses is unknown. It typically involves estimation of regression coefficients via ordinary least squares and their subsequent use to make decisions.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(vectordb_gpt,\"What is linear regression?\" , llm, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a8f5cadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:04.659735Z",
     "start_time": "2023-07-30T19:48:03.331448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Linear regression analysis typically involves estimation of regression coefficients via ordinary least squares and their subsequent use to make decisions.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db_relevance(vectordb_gpt,\"What is linear regression?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94573f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:06.712825Z",
     "start_time": "2023-07-30T19:48:04.662540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Linear regression is a method of estimating a model parameter from observations from a linear model, typically involving estimation of regression coefficients via ordinary least squares and their subsequent use to make decisions.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(elasticdb_gpt,\"What is linear regression?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "787663b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:08.960393Z",
     "start_time": "2023-07-30T19:48:06.717118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Natural language processing (NLP) is an important learning task in natural language processing which involves teaching machines to read and comprehend natural language documents. It is used to build systems that are both fast and accurate, but quality often comes at the cost of speed.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(vectordb_gpt,\"What is Natural language processing?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "87c172fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:10.885596Z",
     "start_time": "2023-07-30T19:48:08.964210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Natural language processing (NLP) is an important learning task in natural language processing which involves teaching machines to read and comprehend natural language documents. It is used to build systems that are both fast and accurate, but quality often comes at the cost of speed.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(elasticdb_gpt,\"What is Natural language processing?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b8d6df13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:59:31.796640Z",
     "start_time": "2023-07-30T19:59:28.956932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Sorry, I don't know how to help with that.\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(vectordb_gpt,\"What is Natural language processing?\" , llm, {\"year\":1990})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92850303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:13.466058Z",
     "start_time": "2023-07-30T19:48:12.223565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Sorry, I don't know how to help with that.\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(elasticdb_gpt,\"What is Natural language processing?\" , llm, {\"year\":1990})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7c440512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:57:05.545989Z",
     "start_time": "2023-07-30T19:57:04.382824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' BERT is a new language representation model called Bidirectional Encoder Representations from Transformers.'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(vectordb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c004813d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:16.007756Z",
     "start_time": "2023-07-30T19:48:14.698342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know how to help with that.\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db_relevance(vectordb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4a56c",
   "metadata": {},
   "source": [
    "## Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d871770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:16.026360Z",
     "start_time": "2023-07-30T19:48:16.012073Z"
    }
   },
   "outputs": [],
   "source": [
    "new_papers = [{\n",
    "    \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n",
    "    \"authors\": \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova\",\n",
    "    \"year\": 2018,\n",
    "    \"paper_id\": 7301,\n",
    "    \"abstract\": \"\"\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.\n",
    "BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\n",
    "\"\"\"\n",
    "},\n",
    "  {\n",
    "      \"title\" : \"Evolution of transfer learning in natural language processing\",\n",
    "       \"authors\": \"Aditya Malte, Pratik Ratadiya\",\n",
    "      \"year\": 2019,\n",
    "       \"paper_id\": 7302,\n",
    "      \"abstract\": \"\"\"In this paper, we present a study of the recent advancements which have helped bring Transfer Learning to NLP through the use of semi-supervised training. We discuss cutting-edge methods and architectures such as BERT, GPT, ELMo, ULMFit among others. Classically, tasks in natural language processing have been performed through rule-based and statistical methodologies. However, owing to the vast nature of natural languages these methods do not generalise well and failed to learn the nuances of language. Thus machine learning algorithms such as Naive Bayes and decision trees coupled with traditional models such as Bag-of-Words and N-grams were used to usurp this problem. Eventually, with the advent of advanced recurrent neural network architectures such as the LSTM, we were able to achieve state-of-the-art performance in several natural language processing tasks such as text classification and machine translation. We talk about how Transfer Learning has brought about the well-known ImageNet moment for NLP. Several advanced architectures such as the Transformer and its variants have allowed practitioners to leverage knowledge gained from unrelated task to drastically fasten convergence and provide better performance on the target task. This survey represents an effort at providing a succinct yet complete understanding of the recent advances in natural language processing using deep learning in with a special focus on detailing transfer learning and its potential advantages.\n",
    "\"\"\"    \n",
    "  },\n",
    "  {\n",
    "       \"title\" : \"BERTQA -- Attention on Steroids\",\n",
    "       \"authors\": \"Ankit Chadha, Rewa Sood\",\n",
    "      \"year\": 2019,\n",
    "        \"paper_id\": 7303,\n",
    "      \"abstract\": \"\"\"In this work, we extend the Bidirectional Encoder Representations from Transformers (BERT) with an emphasis on directed coattention to obtain an improved F1 performance on the SQUAD2.0 dataset. The Transformer architecture on which BERT is based places hierarchical global attention on the concatenation of the context and query. Our additions to the BERT architecture augment this attention with a more focused context to query (C2Q) and query to context (Q2C) attention via a set of modified Transformer encoder units. In addition, we explore adding convolution-based feature extraction within the coattention architecture to add localized information to self-attention. We found that coattention significantly improves the no answer F1 by 4 points in the base and 1 point in the large architecture. After adding skip connections the no answer F1 improved further without causing an additional loss in has answer F1. The addition of localized feature extraction added to attention produced an overall dev F1 of 77.03 in the base architecture. We applied our findings to the large BERT model which contains twice as many layers and further used our own augmented version of the SQUAD 2.0 dataset created by back translation, which we have named SQUAD 2.Q. Finally, we performed hyperparameter tuning and ensembled our best models for a final F1/EM of 82.317/79.442 (Attention on Steroids, PCE Test Leaderboard).\n",
    "\"\"\"             \n",
    "  },\n",
    "    {\n",
    "        \"title\": \"BERT: A Review of Applications in Natural Language Processing and Understanding\",\n",
    "        \"authors\": \"Mikhail Koroteev\",\n",
    "        \"year\": 2021,\n",
    "        \"paper_id\": 7304,\n",
    "        \"abstract\": \"In this review, we describe the application of one of the most popular deep learning-based language models - BERT. The paper describes the mechanism of operation of this model, the main areas of its application to the tasks of text analytics, comparisons with similar models in each task, as well as a description of some proprietary models. In preparing this review, the data of several dozen original scientific articles published over the past few years, which attracted the most attention in the scientific community, were systematized. This survey will be useful to all students and researchers who want to get acquainted with the latest advances in the field of natural language text analysis.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0981f3de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:16.036851Z",
     "start_time": "2023-07-30T19:48:16.029467Z"
    }
   },
   "outputs": [],
   "source": [
    "new_paper_df = pd.DataFrame(new_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be2f0e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:16.053656Z",
     "start_time": "2023-07-30T19:48:16.039589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT: Pre-training of Deep Bidirectional Trans...</td>\n",
       "      <td>Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kris...</td>\n",
       "      <td>2018</td>\n",
       "      <td>7301</td>\n",
       "      <td>We introduce a new language representation mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evolution of transfer learning in natural lang...</td>\n",
       "      <td>Aditya Malte, Pratik Ratadiya</td>\n",
       "      <td>2019</td>\n",
       "      <td>7302</td>\n",
       "      <td>In this paper, we present a study of the recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BERTQA -- Attention on Steroids</td>\n",
       "      <td>Ankit Chadha, Rewa Sood</td>\n",
       "      <td>2019</td>\n",
       "      <td>7303</td>\n",
       "      <td>In this work, we extend the Bidirectional Enco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BERT: A Review of Applications in Natural Lang...</td>\n",
       "      <td>Mikhail Koroteev</td>\n",
       "      <td>2021</td>\n",
       "      <td>7304</td>\n",
       "      <td>In this review, we describe the application of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  BERT: Pre-training of Deep Bidirectional Trans...   \n",
       "1  Evolution of transfer learning in natural lang...   \n",
       "2                    BERTQA -- Attention on Steroids   \n",
       "3  BERT: A Review of Applications in Natural Lang...   \n",
       "\n",
       "                                             authors  year  paper_id  \\\n",
       "0  Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kris...  2018      7301   \n",
       "1                      Aditya Malte, Pratik Ratadiya  2019      7302   \n",
       "2                            Ankit Chadha, Rewa Sood  2019      7303   \n",
       "3                                   Mikhail Koroteev  2021      7304   \n",
       "\n",
       "                                            abstract  \n",
       "0  We introduce a new language representation mod...  \n",
       "1  In this paper, we present a study of the recen...  \n",
       "2  In this work, we extend the Bidirectional Enco...  \n",
       "3  In this review, we describe the application of...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1dce5812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:16.062690Z",
     "start_time": "2023-07-30T19:48:16.057745Z"
    }
   },
   "outputs": [],
   "source": [
    "loader_new = DataFrameLoader(new_paper_df, page_content_column=\"abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f0a69bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:16.078963Z",
     "start_time": "2023-07-30T19:48:16.065453Z"
    }
   },
   "outputs": [],
   "source": [
    "new_splits = sentence_spltter.split_documents(loader_new.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2cad741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:18.376868Z",
     "start_time": "2023-07-30T19:48:16.082522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['068ce2c2-2f12-11ee-96eb-acde48001122',\n",
       " '068d02fc-2f12-11ee-96eb-acde48001122',\n",
       " '068d034c-2f12-11ee-96eb-acde48001122',\n",
       " '068d04f0-2f12-11ee-96eb-acde48001122',\n",
       " '068d059a-2f12-11ee-96eb-acde48001122',\n",
       " '068d05f4-2f12-11ee-96eb-acde48001122',\n",
       " '068d063a-2f12-11ee-96eb-acde48001122',\n",
       " '068d066c-2f12-11ee-96eb-acde48001122',\n",
       " '068d0694-2f12-11ee-96eb-acde48001122',\n",
       " '068d06bc-2f12-11ee-96eb-acde48001122',\n",
       " '068d06e4-2f12-11ee-96eb-acde48001122',\n",
       " '068d070c-2f12-11ee-96eb-acde48001122',\n",
       " '068d0734-2f12-11ee-96eb-acde48001122',\n",
       " '068d0752-2f12-11ee-96eb-acde48001122',\n",
       " '068d077a-2f12-11ee-96eb-acde48001122',\n",
       " '068d07a2-2f12-11ee-96eb-acde48001122',\n",
       " '068d07c0-2f12-11ee-96eb-acde48001122',\n",
       " '068d07e8-2f12-11ee-96eb-acde48001122',\n",
       " '068d0810-2f12-11ee-96eb-acde48001122',\n",
       " '068d082e-2f12-11ee-96eb-acde48001122',\n",
       " '068d0856-2f12-11ee-96eb-acde48001122',\n",
       " '068d087e-2f12-11ee-96eb-acde48001122',\n",
       " '068d089c-2f12-11ee-96eb-acde48001122',\n",
       " '068d08c4-2f12-11ee-96eb-acde48001122',\n",
       " '068d08ec-2f12-11ee-96eb-acde48001122',\n",
       " '068d090a-2f12-11ee-96eb-acde48001122',\n",
       " '068d0932-2f12-11ee-96eb-acde48001122',\n",
       " '068d0950-2f12-11ee-96eb-acde48001122',\n",
       " '068d0978-2f12-11ee-96eb-acde48001122',\n",
       " '068d09a0-2f12-11ee-96eb-acde48001122',\n",
       " '068d09be-2f12-11ee-96eb-acde48001122']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_gpt.add_documents(new_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ee1e8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:20.119534Z",
     "start_time": "2023-07-30T19:48:18.379301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['41726043-6c0f-4365-ba97-f1a85bb378c4',\n",
       " '1ac929e7-89a0-45d1-ab8f-d577517c4378',\n",
       " '4e5ec7fb-78f6-4622-9496-051c8cbaaf31',\n",
       " '3ef93174-3afd-4e7a-be24-0eead264e92c',\n",
       " '8b29ee93-b840-4a9b-83da-e5ef1650af7c',\n",
       " '0a52e562-2d21-4da2-a8fb-5bf9a9e86520',\n",
       " '9c8dd476-6e38-43c8-b81c-b34ca812c036',\n",
       " 'aaa54146-1a4e-45c8-945b-b88d554ed915',\n",
       " 'ef70a13f-335b-4573-81f2-589e2879138a',\n",
       " 'f0802776-f974-4709-aebd-6ff26e7b67f6',\n",
       " '9fefcaaa-6967-4722-95d2-70d960a84b50',\n",
       " '1fe1bd4a-b5c7-42ef-aca8-27b045760107',\n",
       " '33b89edc-cbe7-4af5-9aec-5ae1982e06b4',\n",
       " '89d187bd-5e59-4cb8-be1b-2ffc88bf505f',\n",
       " '9d28d780-c3ce-4252-8da2-a60c9d19093c',\n",
       " 'aad2074d-8dd1-47f5-a763-9c0eeda392d9',\n",
       " '8eb49d91-c385-4b49-b115-a65d07ba7ae3',\n",
       " 'b58cb326-e20f-4794-9ec5-496cebdb7cd2',\n",
       " '30e946b6-4fec-4a18-807a-6e72a05974de',\n",
       " 'de816b25-f9ca-4971-8da5-2f7d99aad187',\n",
       " '294bedb9-2a56-4dd4-b932-c6d13fe292d0',\n",
       " 'de9083aa-dbd8-4dbd-9cd1-77a83d74d2de',\n",
       " '67b771b4-a38e-4730-b202-1c4c1d108292',\n",
       " '40f5e9f7-6443-48e9-a6ba-6f1f44f54823',\n",
       " 'f38063bf-6783-4a5e-b49a-89d58d3a7502',\n",
       " 'b54cfc4b-e7fd-4c4d-a2ba-477a9d262cda',\n",
       " 'af1fe645-ed32-4554-9531-895297a097dd',\n",
       " 'f9d7eada-fd42-4f09-a1ca-e05f0da4f6d5',\n",
       " 'e3c78f71-c003-490e-a716-8470795e74f1',\n",
       " '3eb350b5-29ed-417d-8289-a65a87010eb5',\n",
       " 'a55b4753-5e57-4c05-8008-a53658412c49']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticdb_gpt.add_documents(new_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ffced776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:21.451572Z",
     "start_time": "2023-07-30T19:48:20.121763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' BERT is a new language representation model called Bidirectional Encoder Representations from Transformers.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(vectordb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1cd77b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:23.195287Z",
     "start_time": "2023-07-30T19:48:21.455235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' BERT is a new language representation model called Bidirectional Encoder Representations from Transformers.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db_relevance(vectordb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68327365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:24.730276Z",
     "start_time": "2023-07-30T19:48:23.199306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' BERT is a new language representation model called Bidirectional Encoder Representations from Transformers.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(elasticdb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "40b596b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:26.353034Z",
     "start_time": "2023-07-30T19:48:24.734028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know how to help with that.\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db_relevance(vectordb_gpt,\"How is bert an improvement?\" , llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b785909",
   "metadata": {},
   "source": [
    "## Chatting with your data: Final Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e8daff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:26.391460Z",
     "start_time": "2023-07-30T19:48:26.357217Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fbccf78d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:26.433129Z",
     "start_time": "2023-07-30T19:48:26.394559Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "retriever=vectordb_gpt.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e797ac09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:28.302419Z",
     "start_time": "2023-07-30T19:48:26.438929Z"
    }
   },
   "outputs": [],
   "source": [
    "question = \"What is Natural language processing?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2a6ffbf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:28.318227Z",
     "start_time": "2023-07-30T19:48:28.306452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. It is used to analyze and understand natural language, as well as to enable computers to generate and manipulate natural language.'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fa5b9862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:31.177247Z",
     "start_time": "2023-07-30T19:48:28.323109Z"
    }
   },
   "outputs": [],
   "source": [
    "question = \"What are its real life applications?\"\n",
    "result2 = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "38543a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:31.196232Z",
     "start_time": "2023-07-30T19:48:31.181666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Natural Language Processing is used in a variety of real-life applications, such as text classification, machine translation, question answering, tagging, and parsing. It is also used in voice recognition, sentiment analysis, and automated customer service.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " result2[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c0d9a92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:31.210604Z",
     "start_time": "2023-07-30T19:48:31.199306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0301\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "332c134b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:34.397438Z",
     "start_time": "2023-07-30T19:48:31.249096Z"
    }
   },
   "outputs": [],
   "source": [
    "import gradio\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history_ui\",\n",
    "    return_messages=True\n",
    ")\n",
    "retriever=vectordb_gpt.as_retriever()\n",
    "    \n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=\"stuff\", \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "def chat(message, history=None):\n",
    "    history = history or []\n",
    "    response = qa({\"question\": message, \"chat_history\":history})['answer']\n",
    "    history.append((message, response))\n",
    "    return history, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d71bb01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T19:48:44.198980Z",
     "start_time": "2023-07-30T19:48:34.400163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/q4kkg14x6c9bg29754hkb_yr0000gn/T/ipykernel_45302/3380930186.py:2: GradioDeprecationWarning: The 'color_map' parameter has been deprecated.\n",
      "  chatbot = gradio.Chatbot(color_map=(\"green\", \"gray\"))\n",
      "/var/folders/3c/q4kkg14x6c9bg29754hkb_yr0000gn/T/ipykernel_45302/3380930186.py:3: GradioDeprecationWarning: `allow_screenshot` parameter is deprecated, and it has no effect\n",
      "  interface = gradio.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://deb19025297d750c63.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://deb19025297d750c63.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection.load()\n",
    "chatbot = gradio.Chatbot(color_map=(\"green\", \"gray\"))\n",
    "interface = gradio.Interface(\n",
    "    chat,\n",
    "    [\"text\", \"state\"],\n",
    "    [chatbot, \"state\"],\n",
    "    allow_screenshot=False,\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "interface.launch(inline=True, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4b990",
   "metadata": {},
   "source": [
    "There are two arch types bert vs gpt : People would want to describe focus on architechtures\n",
    "\n",
    "1)why aare we doing preprocessing?\n",
    "\n",
    "2) MMR vs similarity searching\n",
    "\n",
    "3) Run the notebooks in advance. \n",
    "\n",
    "\n",
    "4) What gradio is. Add Gradio in slide\n",
    "\n",
    "5) COntext optimization big data approaches in slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead53220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DatahackSummitSemanticSearch",
   "language": "python",
   "name": "datahacksummitsemanticsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
